import gc
import numpy as np
from data_analysis.utils import math_utils, utils

def train_val_split(x_set, y_set, val_percentage=0.0, shuffle=True):
    """Splits a data set into train and validation subsets for fitting
    a model

    Parameters:

    x_set: numpy.ndarray
        X set of the data

    y_set: numpy..ndarray
        Y set of the data

    val_percentage: float
        Percentage of the data, from 0 to 1,  that will be used as
        validation data
    
    shuffle: boolean
        If true shuffles the set
    
    Returns:

    x_set_train:numpy.ndarray
    y_set_train:numpy.ndarray
    x_set_val:numpy.ndarray
    y_set_val:numpy.ndarray
    """

    if shuffle:
        x_y_set = list(zip(x_set, y_set))
        np.random.shuffle(x_y_set)
        x_set = list()
        y_set = list()
        for x, y in x_y_set:
            x_set.append(x)
            y_set.append(y)
        x_set = np.array(x_set)
        y_set = np.array(y_set)

    split = np.math.ceil(len(x_set)*val_percentage)
    x_set_val = x_set[:split]
    x_set_train = x_set[split:]
    y_set_val = y_set[:split]
    y_set_train = y_set[split:]

    return x_set_train, y_set_train, x_set_val, y_set_val


def most_even_split(index_range, n_splits):
    """Slices a index array with the given number of splits in the most even manner possible
    Example:
    The range(13) object can be seen as
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
    divided in 5 splits could happen in any number of ways but this method splits it the most 
    even way possible that is two splits with 2 events and 3 splits with 3 elements.
    then the funcition returns:
    [(0,1,2), (3,4,5), (6,7,8), (9,10), (11,12)]

    Parameters:

    index_range: 1D array-like
        A 1D iterable with its elements being ints that simbolizes indexes generated by a range
    
    n_splits: int
        Number of splits to be done

    Returns:

    splits: list
        A list with each item being a split array with the indexes of that split
    """
    events = len(index_range)
    index_start = index_range[0]
    index_end = index_range[-1] + 1
    events_per_split = int(events/n_splits)
    remainders = events%n_splits
    if remainders == 0:     #The array is splitted evenly
        splits =  [range(split_start, split_start+events_per_split) for split_start in range(index_start, index_end, events_per_split)]
    else:
        #Mouting the uneven splits
        splits = list()
        start = index_start
        #events_to_add = math_utils.euclidean_algorithm(remainders, n_splits)
        for _ in range(n_splits):
            if remainders>0:
                to_add = events_per_split + 1
                remainders -= 1
            elif remainders == 0:
                to_add = events_per_split
            else:
                raise ValueError(f'Reached a negative remainder: {remainders}')
            splits.append(range(start, start+to_add))
            start += to_add
    return splits

class RangedDataSplitter():
    """ Splitter for ranged data
    Attributes:
    
    data: numpy.ndarray
        Array with the data
    
    labels: 1D array-like
        Array with the correct labels of the data
    
    ranges: 2D array-like
        Array with the the ranges for each class where ranges[i] returns the ranges
        for the class i
    
    nov_cls: int
        Class to be treated as novelty. Defaults to None and if so no class is tretaed as novelty."""

    def __init__(self, data, labels, ranges):
        self.data = np.array(data)
        self.labels = np.array(labels)
        self.classes = np.unique(labels)
        self.ranges = np.array(ranges)
        self.nov_cls = None
        
    def set_novelty(self, nov_cls, to_known_value):
        """Sets the dataset novelty class

        Parameters:

        nov_cls: str
            Name of the class to be treated as novelty
        
        to_known_value: 
            Callable that recieves the value of a non novelty class and returns a new value with
            nov_cls treated as novelty.
        """

        if nov_cls in self.classes:
            self.nov_cls = nov_cls
        else:
            raise ValueError('The given novelty class is not on the classes parameter.')
        if callable(to_known_value):
            self.to_known_value = to_known_value
        else:
            raise ValueError('The to_known_value parameter must be callable')

    def kfold_split(self, n_splits=3, shuffle=False):
        """ Cross validation method realized on the lofar data.
        This method consists into dividing each run into n_splits in the most equal manner possible.
        Then, one split is selected for test, other for validation and the rest for training, therefore n_splits minimun is 3.
        Each correleated split from each run is then shuffled with the others resulting in the final test, val and training sets.
        If a novelty class is defined, it is added to the test set int the end.

        Parameters:

        n_splits: int > 3
            Number of splits to be made

        shuffle: bool
            If True shuffles the data

        Yields:

        x_test, y_test, x_val, y_val, x_train, y_train
        """
        if n_splits<3:
            raise ValueError('The minimun number of splits is 3.')
        
        if self.nov_cls is None:
            x_known, y_known, known_ranges = self.data, self.labels, self.ranges
        else:
            x_known, y_known, known_ranges, x_novelty, y_novelty, novelty_ranges = self._remove_novelty()
        
        for test_index, val_index, train_index in self._range_kfold_split(known_ranges, n_splits, shuffle):

            #Collecting garbage
            gc.collect()

            x_train = x_known[train_index]
            y_train = y_known[train_index]
            x_val = x_known[val_index]
            y_val = y_known[val_index]

            if self.nov_cls is None:
                x_test = x_known[test_index]
                y_test = y_known[test_index]                
            else:
                x_test = np.concatenate((x_novelty, x_known[test_index]), axis=0)
                y_test = np.concatenate((y_novelty, y_known[test_index]), axis=0)
                #Compensating from the class taken out as novelty
                y_train = np.vectorize(self.to_known_value)(y_train)
                y_val = np.vectorize(self.to_known_value)(y_val)
            
                if shuffle:
                    x_test, y_test = utils.shuffle_pair(x_test, y_test)
                    
            yield x_test, y_test, x_val, y_val, x_train, y_train

    def leave1_range_out_split(self, val_percentage=0, shuffle=True):
        """Crosss validation method realized on the lofar data.
        This method treates the test data as one run for each loop and the rest as train data (a percentage can be
        treated as validation data if val_percentage was passed in self.compile).
        If a novelty class is defined it ts added to the test set.

        Parameters:

        val_percentage: float
            Float value of the percentage of the data to be treated as validation data.
            If not passed the generatror does not generate x_val and y_val

        shuffle: bool
            If true shuffles the data
        
        Yields:

        x_test, y_test, x_val, y_val, x_train, y_train
        """

        #Collecting garbage
        gc.collect()

        if self.nov_cls is None:
            x_known, y_known, known_ranges = self.data, self.labels, self.ranges
        else:
            x_known, y_known, known_ranges, x_novelty, y_novelty, _ = self._remove_novelty()

        for class_out, train_index, test_index in self._leave1_range_out(x_known, y_known, known_ranges, shuffle):
            #Collecting garbage
            gc.collect()

            if val_percentage != 0:
                x_train, y_train, x_val, y_val = train_val_split(x_known[train_index], y_known[train_index], val_percentage)
                if self.nov_cls is None:
                    x_test = x_known[test_index]
                    y_test = y_known[test_index]                
                else:
                    x_test = np.concatenate((x_novelty, x_known[test_index]), axis=0)
                    y_test = np.concatenate((y_novelty, y_known[test_index]), axis=0)
                    #Compensating from the class taken out as novelty
                    y_train = np.apply_along_axis(self.to_known_value, axis=0, arr=y_train)
                    y_val = np.apply_along_axis(self.to_known_value, axis=0, arr=y_val)
                    if shuffle:
                        x_test, y_test = utils.shuffle_pair(x_test, y_test)
                        
                yield class_out, x_test, y_test, x_val, y_val, x_train, y_train
            else:
                x_train = x_known[train_index]
                y_train = y_known[train_index]
                if self.nov_cls is None:
                    x_test = x_known[test_index]
                    y_test = y_known[test_index]                
                else:
                    x_test = np.concatenate((x_novelty, x_known[test_index]), axis=0)
                    y_test = np.concatenate((y_novelty, y_known[test_index]), axis=0)
                    #Compensating from the class taken out as novelty
                    y_train = np.apply_along_axis(self.to_known_value, axis=0, arr=y_train)
                
                    if shuffle:
                        x_test, y_test = utils.shuffle_pair(x_test, y_test)
                yield class_out, x_test, y_test, x_train, y_train

    @staticmethod
    def _range_kfold_split(index_ranges, n_splits, shuffle):
        """This method splits each range in n_splits. Then one split it is selected for test, other for validation and
        the rest for training. Splits of same type in each range are then shuffled together

        Parameters:

        index_ranges: 1D array-like
            Range simbolizing the index of the data to be splitted

        n_splits: int
            Number of splits to be made

        shuffle: bool
            If True shuffles the data
        
        Yields:
        test_index, val_index, train_index
        """

        index_splitted = list()

        for index_range in index_ranges:
            splits = most_even_split(index_range,n_splits)
            if shuffle:
                np.random.shuffle(splits)
            index_splitted.append(splits)
        
        index_splitted = np.array(index_splitted).T

        for test_split, val_split in zip(range(n_splits),utils.LoopRange(0,n_splits, num_samples=n_splits, initial_value=1)):
            splits_arr = np.arange(n_splits)
            train_splits = np.all(np.stack((splits_arr != test_split,  splits_arr!= val_split),axis=0), axis=0)
            test_index = np.hstack(index_splitted[test_split])
            val_index = np.hstack(index_splitted[val_split])
            train_index = np.hstack(np.hstack(index_splitted[train_splits]))

            if shuffle:
                np.random.shuffle(test_index)
                np.random.shuffle(val_index)
                np.random.shuffle(train_index)

            yield test_index, val_index, train_index

    @staticmethod
    def _leave1_range_out(x_set, y_set, ranges, shuffle):
        """Generator that returns the range of the run left out for test and the rest for fitting
        
        Parameters:

        x_set: np.ndarray
            X set of the dataset to be splitted

        y_set: np.ndarray
            Y set of the dataset to be splitted
        
        ranges: 2D array-like
            Array representing the ranges for each class where the ranges array from ranges[i]
            is the ranges from class i

        shuffle: bool
            If True, shuffles the data

        Yields:

        class_out:
            Class that was taken out

        train_ranges:
            Training ranges

        test_range:
            Test range
        """

        classes = np.unqiue(y_set)
        for class_out, class_ranges in zip(classes, ranges):
            for range_out_index in range(len(class_ranges)):
                train_ranges = list(class_ranges)
                test_range = train_ranges.pop(range_out_index)
                train_ranges = np.hstack(np.hstack(train_ranges))
                test_range = np.array(test_range)
                if shuffle:
                    np.random.shuffle(train_ranges)
                    np.random.shuffle(test_range)

                yield class_out, train_ranges, test_range
    
    @staticmethod
    def _rearrange_ranges(ranges):
        """Rearanges a ranges array to connect the ends of unconnected arrays as a results of considering
        a class as novelty"""
        new_ranges = list()
        current_range_start = 0
        for range_ in ranges:
            if range_[0] == current_range_start:
                new_ranges.append(range_)
            else:
                new_range = np.arange(current_range_start, current_range_start+len(range_))
                new_ranges.append(new_range)
            current_range_start += len(range_)
        return np.array(new_ranges)

    def _remove_novelty(self):
        """Removes a class from the data for treating it as novelty"""
        ranges_index = list()
        for range_ in self.ranges:
            ranges_index.append(self.labels[range_[0]])
        ranges_index = np.array(ranges_index)
        x_known = self.data[self.labels != self.nov_cls]
        y_known = self.labels[self.labels != self.nov_cls]
        known_ranges = self._rearrange_ranges(self.ranges[ranges_index != self.nov_cls])
        x_novelty = self.data[self.labels == self.nov_cls]
        y_novelty = self.labels[self.labels == self.nov_cls]
        novelty_ranges = self._rearrange_ranges(self.ranges[ranges_index == self.nov_cls])

        return x_known, y_known, known_ranges, x_novelty, y_novelty, novelty_ranges

    def __print__(self):
        parameters = self.__dict__
        print('The current state of the model parameters are:')
        for key, value in parameters.items():
            print(f'{key} : {value}')